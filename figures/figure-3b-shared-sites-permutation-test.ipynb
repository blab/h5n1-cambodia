{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3b: H5N1 shared SNPs permutation test\n",
    "\n",
    "June 6, 2019\n",
    "\n",
    "Trevor suggested that I run some simulations randomly assigning polymorphic sites to random parts of the genome and then seeing how much sharing occurs when this is random. The idea here is that we have identified 9 polymorphic amino acid sites that are shared in at least 2 samples. However, we don't have any great idea about whether that is more or less sharing than we would expect by chance alone. The idea is to do the following: \n",
    "\n",
    "1. For each gene and individual, calculate the number of amino acid polymorphisms present in the sample. Record that. \n",
    "2. Simulate the same number of individuals and gene segments that we have, and assign them polymorphism at random sites.\n",
    "3. Compute how many SNPs polymorphic sites are shared among at least 2 samples. \n",
    "4. Repeat for 10,000 simulations to generate a distribution. \n",
    "5. Compare with the actual number of observed shared sites (3 and 9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import sys, subprocess, glob, os, shutil, re, importlib, Bio, csv\n",
    "from subprocess import call\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from collections import Counter\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors \n",
    "human_color = \"#C75643\"\n",
    "duck_color = \"#545AB7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Write the simulator \n",
    "\n",
    "I will first write the simulator that will take as input an array of samples with polymorphic sites in their genomes and the number of simulations to perform. This will then randomly assign the sites and run the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_shared_sites(polymorphisms_array, num_sites_array, num_sims):\n",
    "    \n",
    "    iteration_results = {\"PB2\":[], \"PB1\":[], \"PA\":[], \"HA\":[], \"NP\":[],\"NA\":[], \"M1\":[], \"M2\":[], \"NS1\":[], \"NEP\":[]}\n",
    "    \n",
    "    for i in range(0, num_sims):\n",
    "        \n",
    "        results = {\"PB2\":[], \"PB1\":[], \"PA\":[], \"HA\":[], \"NP\":[],\"NA\":[], \"M1\":[], \"M2\":[], \"NS1\":[], \"NEP\":[]}\n",
    "    \n",
    "        for sample in polymorphisms_array:\n",
    "            for gene in polymorphisms_array[sample]:\n",
    "                num_possible_sites = range(0,num_sites_array[sample][gene])     # define the number of possible sites\n",
    "                num_sites_to_draw = polymorphisms_array[sample][gene]           # specify how many sites to choose\n",
    "                try:\n",
    "                    random_draw = (random.sample(num_possible_sites, num_sites_to_draw))   # take a random draw\n",
    "                except: \n",
    "                    print(\"there was an error with the number of available sites vs. the draw size\")\n",
    "                    print(sample, gene, num_possible_sites, num_sites_to_draw)\n",
    "            \n",
    "            \n",
    "                # write results to their respective lists\n",
    "                for r in random_draw:\n",
    "                    results[gene].append(r)\n",
    "        #print(results)\n",
    "        \n",
    "        # once iteration is over, count the number of repeat elements in each list \n",
    "        for gene in results:\n",
    "            count=Counter(results[gene]).values()\n",
    "            #print(count)\n",
    "            \n",
    "            more_than_once = 0\n",
    "            for i in count:\n",
    "                if i > 1:\n",
    "                    more_than_once += 1\n",
    "            \n",
    "            iteration_results[gene].append(more_than_once)\n",
    "    \n",
    "    #print(iteration_results)\n",
    "    return(iteration_results)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate the correct input arrays from actual data\n",
    "\n",
    "I now need to actually populate these arrays with the proper values for each sample (how many polymorphic sites are present and how many amino acid sites had the possibility of having a SNP called there). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a: generate SNP array\n",
    "\n",
    "Use the duplicate reads removed SNP data to generate a dictionary of the number of amino acid site changes (both synonyous and nonsynonymous) within the coding region for each gene for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use duplicate reads removed data\n",
    "snps_file = \"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/Cambodia_H5_sequence_raw_data/combined_human_and_bird_usable_subset/combined_vcfs_nodups/combined_variants_nodups_2018-11-13.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AA4KNL706F512_A_Cambodia_X0128304_2013': {'PB2': 10, 'PB1': 0, 'PA': 5, 'HA': 9, 'NP': 7, 'NA': 4, 'M1': 6, 'M2': 1, 'NS1': 4, 'NEP': 1}, 'AJ4MBL723F512_A_CAMBODIA_V0401301_2011': {'PB2': 6, 'PB1': 8, 'PA': 9, 'HA': 12, 'NP': 6, 'NA': 9, 'M1': 1, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJ4MBL718F513_A_CAMBODIA_V0417301_2011': {'PB2': 2, 'PB1': 0, 'PA': 3, 'HA': 6, 'NP': 2, 'NA': 4, 'M1': 0, 'M2': 1, 'NS1': 0, 'NEP': 0}, 'AJ4MBL720F513_A_Cambodia_W0112303_2012': {'PB2': 3, 'PB1': 4, 'PA': 9, 'HA': 1, 'NP': 6, 'NA': 1, 'M1': 0, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJ4MBL720F514_A_Cambodia_X0125302_2013': {'PB2': 6, 'PB1': 12, 'PA': 2, 'HA': 3, 'NP': 2, 'NA': 2, 'M1': 1, 'M2': 1, 'NS1': 1, 'NEP': 0}, 'AJ4MBL723F514_A_Cambodia_X0207301_2013': {'PB2': 1, 'PB1': 3, 'PA': 8, 'HA': 5, 'NP': 1, 'NA': 2, 'M1': 3, 'M2': 0, 'NS1': 1, 'NEP': 1}, 'AJ4MBL718F515_A_Cambodia_X0219301_2013': {'PB2': 2, 'PB1': 0, 'PA': 3, 'HA': 2, 'NP': 2, 'NA': 1, 'M1': 0, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJ4MBL720F516_A_Cambodia_X1030304_2013': {'PB2': 2, 'PB1': 5, 'PA': 1, 'HA': 3, 'NP': 0, 'NA': 0, 'M1': 3, 'M2': 2, 'NS1': 1, 'NEP': 0}}\n",
      "{'AJJ9KL706F510_A_duck_Cambodia_381W11M4_2013': {'PB2': 4, 'PB1': 1, 'PA': 3, 'HA': 1, 'NP': 1, 'NA': 0, 'M1': 0, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJJ9KL707F511_A_duck_Cambodia_PV027D1_2010': {'PB2': 0, 'PB1': 2, 'PA': 1, 'HA': 1, 'NP': 0, 'NA': 0, 'M1': 1, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJJ9KL707F513_A_duck_Cambodia_083D1_2011': {'PB2': 0, 'PB1': 1, 'PA': 0, 'HA': 1, 'NP': 1, 'NA': 2, 'M1': 1, 'M2': 0, 'NS1': 0, 'NEP': 0}, 'AJJ9KL707F515_A_duck_Cambodia_Y0224301_2014': {'PB2': 0, 'PB1': 0, 'PA': 1, 'HA': 1, 'NP': 0, 'NA': 1, 'M1': 0, 'M2': 0, 'NS1': 2, 'NEP': 2}, 'AH7E5L724F516_A_duck_Cambodia_Y0224304_2014': {'PB2': 1, 'PB1': 0, 'PA': 0, 'HA': 2, 'NP': 8, 'NA': 0, 'M1': 0, 'M2': 0, 'NS1': 0, 'NEP': 0}}\n"
     ]
    }
   ],
   "source": [
    "## first generate the array of the number of SNPs per gene per sample\n",
    "\n",
    "SNPs_human = {}\n",
    "SNPs_duck = {}\n",
    "\n",
    "with open(snps_file, \"r\") as infile: \n",
    "    for line in infile: \n",
    "        if \"reference_position\" not in line: \n",
    "            sample = line.split(\"\\t\")[0]\n",
    "            sample = \"_\".join(sample.split(\"_\")[:-1])\n",
    "            gene = line.split(\"\\t\")[2]\n",
    "            gene = gene.replace(\"_circ\",\"\")\n",
    "            cds_change = line.split(\"\\t\")[7]\n",
    "            aa_change = line.split(\"\\t\")[6]\n",
    "            aa_site = aa_change[3:-3]\n",
    "            \n",
    "            if \"duck\" in sample: \n",
    "                species = \"duck\"\n",
    "            else: \n",
    "                species = \"human\"\n",
    "            \n",
    "            if species == \"human\":\n",
    "                if cds_change == \"synonymous\" or cds_change == \"nonsynonymous\":\n",
    "                    if sample not in SNPs_human:\n",
    "                        SNPs_human[sample] = {\"PB2\":[], \"PB1\":[], \"PA\":[], \"HA\":[], \"NP\":[],\"NA\":[], \"M1\":[], \"M2\":[], \"NS1\":[], \"NEP\":[]}\n",
    "                        SNPs_human[sample][gene].append(aa_site)\n",
    "                    \n",
    "                    elif sample in SNPs_human:\n",
    "                        if aa_site not in SNPs_human[sample][gene]:\n",
    "                            SNPs_human[sample][gene].append(aa_site)\n",
    "\n",
    "            elif species == \"duck\":\n",
    "                if cds_change == \"synonymous\" or cds_change == \"nonsynonymous\":\n",
    "                    if sample not in SNPs_duck:\n",
    "                        SNPs_duck[sample] = {\"PB2\":[], \"PB1\":[], \"PA\":[], \"HA\":[], \"NP\":[],\"NA\":[], \"M1\":[], \"M2\":[], \"NS1\":[], \"NEP\":[]}\n",
    "                        SNPs_duck[sample][gene].append(aa_site)\n",
    "                    \n",
    "                    elif sample in SNPs_duck:\n",
    "                        if aa_site not in SNPs_duck[sample][gene]:\n",
    "                            SNPs_duck[sample][gene].append(aa_site)\n",
    "                        \n",
    "\n",
    "SNPs_human2 = {}\n",
    "SNPs_duck2 = {}\n",
    "\n",
    "for sample in SNPs_human:\n",
    "    SNPs_human2[sample] = {}\n",
    "    for gene in SNPs_human[sample]:\n",
    "        number_aa_snvs = len(SNPs_human[sample][gene])\n",
    "        SNPs_human2[sample][gene] = number_aa_snvs\n",
    "\n",
    "for sample in SNPs_duck:\n",
    "    SNPs_duck2[sample] = {}\n",
    "    for gene in SNPs_duck[sample]:\n",
    "        number_aa_snvs = len(SNPs_duck[sample][gene])\n",
    "        SNPs_duck2[sample][gene] = number_aa_snvs\n",
    "\n",
    "                            \n",
    "print(SNPs_human2)\n",
    "print(SNPs_duck2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: generate array with the number of possible amino acid sites\n",
    "\n",
    "Here I am calculating the number of amino acid sites at which a SNP could have been called based on the pileup file from the duplicate reads removed data. For each site, a SNP should not have been called if the coverage was less than 100x. I am also only including SNPs called within the coding region, so I am using the CDS coordinates from the gtf files for each sample to delineate the number of sites uniquely for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now generate the number of amino acid sites per gene \n",
    "pileup_file_directory = \"/Volumes/gradschool-and-postdoc-backups/post-doc/stored_files_too_big_for_laptop/H5N1_Cambodia_outbreak_study/Cambodia_H5_sequence_raw_data/combined_human_and_bird_usable_subset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "search_string = \"*/coverage_norm_and_duplicate_read_removal/*.nodups.sam.pileup\"\n",
    "\n",
    "pileups = []\n",
    "for f in glob.glob(pileup_file_directory + search_string):\n",
    "    pileups.append(f)\n",
    "    \n",
    "print(len(pileups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gtfs from gtf directory in snpEff folder to get the proper coding regions for each gene and sample \n",
    "gtf_directory = \"/usr/local/bin/snpEff_latest_core/snpEff/data/\"\n",
    "gtfs = []\n",
    "\n",
    "for f in glob.glob(gtf_directory + \"*/genes.gtf\"):\n",
    "    gtfs.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gtf file with coding region coordinates\n",
    "def define_coding_regions(gtf_list):\n",
    "\n",
    "    coding_regions = {\"human\":{}, \"duck\":{}}\n",
    "    \n",
    "    for gtf_file in gtf_list:\n",
    "\n",
    "        with open(gtf_file, \"r\") as csvfile: \n",
    "            reader = csv.reader(csvfile, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if \"CDS\" in row[2]:\n",
    "                    sample = row[0]\n",
    "                    sample = sample.replace(\"_H5\",\"\")\n",
    "                    sample = sample.replace(\"_MP\",\"\")\n",
    "                    sample = sample.replace(\"_N1\",\"\")\n",
    "                    sample = sample.replace(\"_NS\",\"\")\n",
    "\n",
    "                    gene = row[8].replace(\"gene_id \\\"\",\"\")\n",
    "                    gene = gene.replace(\"\\\"\",\"\")\n",
    "                    transcript = gene.split(\";\")[1]\n",
    "                    gene = gene.replace(transcript, \"\")\n",
    "                    gene = gene.replace(\";;\",\"\")\n",
    "                    gene = gene.replace(\"M2 \",\"M2\")\n",
    "                    \n",
    "                    sample = sample.replace(\"_\"+gene, \"\")\n",
    "                    start = int(row[3])\n",
    "                    stop = int(row[4])\n",
    "                    \n",
    "                    if \"duck\" in sample:\n",
    "                        species = \"duck\"\n",
    "                    else: \n",
    "                        species = \"human\"\n",
    "            \n",
    "                    if not sample in coding_regions[species]:\n",
    "                        coding_regions[species][sample] = {}\n",
    "                    #coding_regions[sample].append(gene)\n",
    "                    if not gene in coding_regions[species][sample]:\n",
    "                        coding_regions[species][sample][gene] = []\n",
    "            \n",
    "                    coding_regions[species][sample][gene].append(start)\n",
    "                    coding_regions[species][sample][gene].append(stop)\n",
    "        \n",
    "\n",
    "        # sort the coordinates to make sure they are in the right order\n",
    "        for sample in coding_regions[species]:\n",
    "            for gene in coding_regions[species][sample]:\n",
    "                coding_regions[species][sample][gene] = sorted(coding_regions[species][sample][gene])\n",
    "\n",
    "        \n",
    "    print(coding_regions)\n",
    "    return(coding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': {'AA4KNL706F512_A_Cambodia_X0128304_2013': {'PB2': [28, 2307], 'PB1': [21, 2292], 'PA': [25, 2175], 'HA': [28, 1734], 'NP': [39, 1535], 'NA': [6, 1355], 'M1': [26, 784], 'M2': [26, 51, 740, 1007], 'NS1': [27, 704], 'NEP': [27, 56, 514, 849]}, 'AJ4MBL718F513_A_CAMBODIA_V0417301_2011': {'PB2': [27, 2306], 'PB1': [25, 2298], 'PA': [15, 2165], 'HA': [1, 1707], 'NP': [36, 1532], 'NA': [8, 1357], 'M1': [14, 772], 'M2': [14, 39, 728, 995], 'NS1': [13, 690], 'NEP': [13, 42, 500, 835]}, 'AJ4MBL718F515_A_Cambodia_X0219301_2013': {'PB2': [24, 2303], 'PB1': [21, 2294], 'PA': [13, 2163], 'HA': [1, 1707], 'NP': [36, 1532], 'NA': [10, 1359], 'M1': [14, 772], 'M2': [14, 39, 728, 995], 'NS1': [1, 678], 'NEP': [1, 30, 488, 823]}, 'AJ4MBL720F513_A_Cambodia_W0112303_2012': {'PB2': [13, 2292], 'PB1': [25, 2298], 'PA': [24, 2174], 'HA': [12, 1718], 'NP': [34, 1530], 'NA': [13, 1362], 'M1': [26, 784], 'M2': [26, 51, 740, 1007], 'NS1': [17, 694], 'NEP': [17, 46, 504, 839]}, 'AJ4MBL720F514_A_Cambodia_X0125302_2013': {'PB2': [24, 2303], 'PB1': [21, 2294], 'PA': [19, 2169], 'HA': [1, 1707], 'NP': [44, 1540], 'NA': [6, 1355], 'M1': [14, 772], 'M2': [14, 39, 728, 995], 'NS1': [23, 700], 'NEP': [23, 52, 510, 845]}, 'AJ4MBL720F516_A_Cambodia_X1030304_2013': {'PB2': [15, 2294], 'PB1': [1, 2274], 'PA': [19, 2169], 'HA': [1, 1707], 'NP': [31, 1527], 'NA': [4, 1353], 'M1': [25, 783], 'M2': [25, 50, 739, 1006], 'NS1': [17, 694], 'NEP': [17, 46, 504, 839]}, 'AJ4MBL723F512_A_CAMBODIA_V0401301_2011': {'PB2': [27, 2306], 'PB1': [1, 2274], 'PA': [19, 2169], 'HA': [1, 1707], 'NP': [1, 1497], 'NA': [17, 1366], 'M1': [16, 784], 'M2': [16, 41, 739, 996], 'NS1': [27, 704], 'NEP': [27, 56, 514, 849]}, 'AJ4MBL723F514_A_Cambodia_X0207301_2013': {'PB2': [17, 2296], 'PB1': [1, 2274], 'PA': [13, 2163], 'HA': [1, 1707], 'NP': [45, 1541], 'NA': [6, 1355], 'M1': [20, 778], 'M2': [20, 45, 734, 1001], 'NS1': [13, 690], 'NEP': [13, 42, 500, 835]}}, 'duck': {'AH7E5L724F516_A_duck_Cambodia_Y0224304_2014': {'PB2': [18, 2297], 'PB1': [11, 2284], 'PA': [13, 2163], 'HA': [17, 1720], 'NP': [31, 1527], 'NA': [6, 1355], 'M1': [14, 772], 'M2': [14, 39, 728, 995], 'NS1': [27, 704], 'NEP': [27, 56, 514, 849]}, 'AJJ9KL706F510_A_duck_Cambodia_381W11M4_2013': {'M1': [19, 777], 'M2': [19, 44, 733, 1000], 'HA': [1, 1701], 'NA': [10, 1359], 'NP': [35, 1531], 'NS1': [27, 704], 'NEP': [27, 56, 514, 849], 'PA': [19, 2169], 'PB1': [20, 2293], 'PB2': [28, 2307]}, 'AJJ9KL707F511_A_duck_Cambodia_PV027D1_2010': {'PB2': [28, 2307], 'PB1': [25, 2298], 'PA': [21, 2171], 'HA': [12, 1718], 'NP': [31, 1527], 'NA': [10, 1359], 'M1': [26, 784], 'M2': [26, 51, 740, 1007], 'NS1': [21, 698], 'NEP': [21, 50, 508, 843]}, 'AJJ9KL707F513_A_duck_Cambodia_083D1_2011': {'PB2': [28, 2307], 'PB1': [9, 2282], 'PA': [25, 2175], 'HA': [10, 1716], 'NP': [34, 1530], 'NA': [10, 1359], 'M1': [1, 759], 'M2': [1, 26, 715, 982], 'NS1': [19, 696], 'NEP': [19, 48, 506, 841]}, 'AJJ9KL707F515_A_duck_Cambodia_Y0224301_2014': {'PB2': [16, 2295], 'PB1': [9, 2282], 'PA': [25, 2175], 'HA': [1, 1707], 'NP': [31, 1527], 'NA': [8, 1357], 'M1': [16, 774], 'M2': [16, 41, 730, 997], 'NS1': [27, 704], 'NEP': [27, 56, 514, 849]}}}\n"
     ]
    }
   ],
   "source": [
    "# fun coding regions analysis\n",
    "coding_regions = define_coding_regions(gtfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use coding regions to define coverage over those coding regions\n",
    "coverage = {\"duck\":{}, \"human\":{}}\n",
    "\n",
    "for p in pileups: \n",
    "    with open(p, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            identifier = line.split(\"\\t\")[0]\n",
    "            gene = identifier.split(\"_\")[-1]\n",
    "            sample = identifier.replace(\"_\" + gene, \"\")\n",
    "            depth = line.split(\"\\t\")[3]\n",
    "            site = int(line.split(\"\\t\")[1])\n",
    "            \n",
    "            if \"duck\" in sample:\n",
    "                species = \"duck\"\n",
    "            else: \n",
    "                species = \"human\"\n",
    "                        \n",
    "            # edit gene names THIS WILL NEED TO FIXED TO ACTUALLY HAVE M AND NS BE CORRECT\n",
    "            gene = gene.replace(\"H5\",\"HA\")\n",
    "            gene = gene.replace(\"N1\",\"NA\")\n",
    "            \n",
    "            # read in coding region coordinates\n",
    "            if gene != \"MP\" and gene != \"NS\":\n",
    "                cds = coding_regions[species][sample][gene]\n",
    "            elif gene == \"MP\":\n",
    "                cds1 = coding_regions[species][sample][\"M1\"]\n",
    "                cds2 = coding_regions[species][sample][\"M2\"]\n",
    "            elif gene == \"NS\":\n",
    "                cds1 = coding_regions[species][sample][\"NS1\"]\n",
    "                cds2 = coding_regions[species][sample][\"NEP\"]\n",
    "            \n",
    "            \n",
    "            # run for all genes not M and NS\n",
    "            if int(depth) >= 100 and (site >= cds[0] or site <= cds[1]) and gene != \"MP\" and gene != \"NS\":\n",
    "            \n",
    "                if sample not in coverage[species]: \n",
    "                    coverage[species][sample] = {\"PB2\":0, \"PB1\":0, \"PA\":0, \"HA\":0, \"NP\":0,\"NA\":0, \"M1\":0, \"M2\":0, \"NS1\":0, \"NEP\":0}\n",
    "                    coverage[species][sample][gene] += 1\n",
    "            \n",
    "                elif sample in coverage[species]: \n",
    "                    coverage[species][sample][gene] += 1\n",
    "                    \n",
    "            # run for M \n",
    "            elif int(depth) >= 100 and gene == \"MP\":\n",
    "                if (site >= cds2[0] and site <= cds2[1]) or (site >= cds2[2] and site <= cds2[3]):\n",
    "                    if sample not in coverage[species]: \n",
    "                        coverage[species][sample] = {\"PB2\":0, \"PB1\":0, \"PA\":0, \"HA\":0, \"NP\":0,\"NA\":0, \"M1\":0, \"M2\":0, \"NS1\":0, \"NEP\":0}\n",
    "                        coverage[species][sample][\"M2\"] += 1\n",
    "            \n",
    "                    elif sample in coverage[species]: \n",
    "                        coverage[species][sample][\"M2\"] += 1\n",
    "                \n",
    "                if site >= cds1[0] and site <= cds1[1]:\n",
    "                    if sample not in coverage[species]: \n",
    "                        coverage[species][sample] = {\"PB2\":0, \"PB1\":0, \"PA\":0, \"HA\":0, \"NP\":0,\"NA\":0, \"M1\":0, \"M2\":0, \"NS1\":0, \"NEP\":0}\n",
    "                        coverage[species][sample][\"M1\"] += 1\n",
    "            \n",
    "                    elif sample in coverage[species]: \n",
    "                        coverage[species][sample][\"M1\"] += 1\n",
    "            \n",
    "            # run for NS            \n",
    "            elif int(depth) >= 100 and gene == \"NS\":\n",
    "                if (site >= cds2[0] and site <= cds2[1]) or (site >= cds2[2] and site <= cds2[3]):\n",
    "                    if sample not in coverage[species]: \n",
    "                        coverage[species][sample] = {\"PB2\":0, \"PB1\":0, \"PA\":0, \"HA\":0, \"NP\":0,\"NA\":0, \"M1\":0, \"M2\":0, \"NS1\":0, \"NEP\":0}\n",
    "                        coverage[species][sample][\"NEP\"] += 1\n",
    "            \n",
    "                    elif sample in coverage[species]: \n",
    "                        coverage[species][sample][\"NEP\"] += 1\n",
    "                \n",
    "                if site >= cds1[0] and site <= cds1[1]:\n",
    "                    if sample not in coverage[species]: \n",
    "                        coverage[species][sample] = {\"PB2\":0, \"PB1\":0, \"PA\":0, \"HA\":0, \"NP\":0,\"NA\":0, \"M1\":0, \"M2\":0, \"NS1\":0, \"NEP\":0}\n",
    "                        coverage[species][sample][\"NS1\"] += 1\n",
    "            \n",
    "                    elif sample in coverage[species]: \n",
    "                        coverage[species][sample][\"NS1\"] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AJ4MBL718F515_A_Cambodia_X0219301_2013': {'PB2': 740, 'PB1': 738, 'PA': 708, 'HA': 97, 'NP': 482, 'NA': 434, 'M1': 237, 'M2': 86, 'NS1': 201, 'NEP': 102}, 'AJ4MBL720F516_A_Cambodia_X1030304_2013': {'PB2': 700, 'PB1': 472, 'PA': 691, 'HA': 513, 'NP': 477, 'NA': 433, 'M1': 240, 'M2': 88, 'NS1': 212, 'NEP': 106}, 'AJ4MBL718F513_A_CAMBODIA_V0417301_2011': {'PB2': 739, 'PB1': 747, 'PA': 709, 'HA': 476, 'NP': 484, 'NA': 431, 'M1': 236, 'M2': 86, 'NS1': 206, 'NEP': 102}, 'AJ4MBL720F513_A_Cambodia_W0112303_2012': {'PB2': 733, 'PB1': 744, 'PA': 712, 'HA': 484, 'NP': 482, 'NA': 429, 'M1': 239, 'M2': 87, 'NS1': 206, 'NEP': 102}, 'AJ4MBL720F514_A_Cambodia_X0125302_2013': {'PB2': 733, 'PB1': 741, 'PA': 710, 'HA': 222, 'NP': 483, 'NA': 434, 'M1': 238, 'M2': 89, 'NS1': 214, 'NEP': 107}, 'AJ4MBL723F514_A_Cambodia_X0207301_2013': {'PB2': 737, 'PB1': 739, 'PA': 711, 'HA': 489, 'NP': 486, 'NA': 430, 'M1': 238, 'M2': 86, 'NS1': 203, 'NEP': 99}, 'AA4KNL706F512_A_Cambodia_X0128304_2013': {'PB2': 740, 'PB1': 0, 'PA': 690, 'HA': 552, 'NP': 478, 'NA': 433, 'M1': 240, 'M2': 88, 'NS1': 216, 'NEP': 112}, 'AJ4MBL723F512_A_CAMBODIA_V0401301_2011': {'PB2': 741, 'PB1': 734, 'PA': 707, 'HA': 320, 'NP': 470, 'NA': 430, 'M1': 238, 'M2': 86, 'NS1': 212, 'NEP': 103}}\n",
      "{'AJJ9KL706F510_A_duck_Cambodia_381W11M4_2013': {'PB2': 731, 'PB1': 744, 'PA': 704, 'HA': 536, 'NP': 474, 'NA': 433, 'M1': 234, 'M2': 88, 'NS1': 212, 'NEP': 107}, 'AJJ9KL707F511_A_duck_Cambodia_PV027D1_2010': {'PB2': 746, 'PB1': 748, 'PA': 708, 'HA': 530, 'NP': 484, 'NA': 434, 'M1': 238, 'M2': 88, 'NS1': 211, 'NEP': 104}, 'AJJ9KL707F513_A_duck_Cambodia_083D1_2011': {'PB2': 752, 'PB1': 747, 'PA': 718, 'HA': 541, 'NP': 481, 'NA': 436, 'M1': 232, 'M2': 89, 'NS1': 212, 'NEP': 112}, 'AJJ9KL707F515_A_duck_Cambodia_Y0224301_2014': {'PB2': 731, 'PB1': 738, 'PA': 700, 'HA': 529, 'NP': 479, 'NA': 433, 'M1': 237, 'M2': 88, 'NS1': 212, 'NEP': 110}, 'AH7E5L724F516_A_duck_Cambodia_Y0224304_2014': {'PB2': 674, 'PB1': 390, 'PA': 651, 'HA': 540, 'NP': 476, 'NA': 421, 'M1': 237, 'M2': 89, 'NS1': 212, 'NEP': 112}}\n"
     ]
    }
   ],
   "source": [
    "## now go through and divide values by 3 to get the approximate number of codons that could have been called as \n",
    "## polymorphic \n",
    "\n",
    "aa_coverages_human = {}\n",
    "aa_coverages_duck = {}\n",
    "\n",
    "for sample in coverage[\"human\"]: \n",
    "    aa_coverages_human[sample] = {}\n",
    "    for gene in coverage[\"human\"][sample]: \n",
    "        \n",
    "        nuc_sites = coverage[\"human\"][sample][gene]\n",
    "        aa_value = int(nuc_sites/3)\n",
    "        aa_coverages_human[sample][gene] = aa_value\n",
    "        \n",
    "for sample in coverage[\"duck\"]: \n",
    "    aa_coverages_duck[sample] = {}\n",
    "    for gene in coverage[\"duck\"][sample]: \n",
    "        \n",
    "        nuc_sites = coverage[\"duck\"][sample][gene]\n",
    "        aa_value = int(nuc_sites/3)\n",
    "        aa_coverages_duck[sample][gene] = aa_value\n",
    "\n",
    "        \n",
    "        \n",
    "print(aa_coverages_human)\n",
    "print(aa_coverages_duck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 100000\n",
    "\n",
    "human_data = simulate_shared_sites(SNPs_human2, aa_coverages_human, num_sims)\n",
    "duck_data = simulate_shared_sites(SNPs_duck2, aa_coverages_duck, num_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PB2</th>\n",
       "      <th>PB1</th>\n",
       "      <th>PA</th>\n",
       "      <th>HA</th>\n",
       "      <th>NP</th>\n",
       "      <th>NA</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>NS1</th>\n",
       "      <th>NEP</th>\n",
       "      <th>full_genome</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PB2  PB1  PA  HA  NP  NA  M1  M2  NS1  NEP  full_genome   host\n",
       "0      0    0    0   1   3   0   0   1   0    0    0            5  human\n",
       "1      1    0    0   0   1   0   0   0   0    0    0            1  human\n",
       "2      2    0    1   2   1   0   1   0   1    0    0            6  human\n",
       "3      3    0    0   2   2   0   0   1   0    0    0            5  human\n",
       "4      4    1    0   0   1   1   1   0   1    0    0            5  human"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "df_human = pd.DataFrame(human_data, columns=human_data.keys())\n",
    "df_human = df_human.reset_index()\n",
    "df_human[\"full_genome\"] = df_human['PB2'] + df_human['PB1'] + df_human['PA'] + df_human['HA'] + df_human['NP'] + df_human['NA'] + df_human['M1'] + df_human['M2'] + df_human['NS1'] + df_human['NEP']\n",
    "df_human[\"host\"] = \"human\"\n",
    "\n",
    "df_duck = pd.DataFrame(duck_data, columns=duck_data.keys())\n",
    "df_duck = df_duck.reset_index()\n",
    "df_duck[\"full_genome\"] = df_duck['PB2'] + df_duck['PB1'] + df_duck['PA'] + df_duck['HA'] + df_duck['NP'] + df_duck['NA'] + df_duck['M1'] + df_duck['M2'] + df_duck['NS1'] + df_duck['NEP']\n",
    "df_duck[\"host\"] = \"duck\"\n",
    "\n",
    "df = pd.concat([df_human, df_duck])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-2019-06-04.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>PB2</th>\n",
       "      <th>PB1</th>\n",
       "      <th>PA</th>\n",
       "      <th>HA</th>\n",
       "      <th>NP</th>\n",
       "      <th>NA</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>NS1</th>\n",
       "      <th>NEP</th>\n",
       "      <th>full_genome</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  PB2  PB1  PA  HA  NP  NA  M1  M2  NS1  NEP  full_genome  \\\n",
       "0           0      0    0    0   1   3   0   0   1   0    0    0            5   \n",
       "1           1      1    0    0   0   1   0   0   0   0    0    0            1   \n",
       "2           2      2    0    1   2   1   0   1   0   1    0    0            6   \n",
       "3           3      3    0    0   2   2   0   0   1   0    0    0            5   \n",
       "4           4      4    1    0   0   1   1   1   0   1    0    0            5   \n",
       "\n",
       "    host  \n",
       "0  human  \n",
       "1  human  \n",
       "2  human  \n",
       "3  human  \n",
       "4  human  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataframe back in \n",
    "df = pd.read_table(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-2019-06-04.txt\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "%%R -w 800 -h 500 -u px -i df,human_color,duck_color  # this sets the size of the plot...otherwise, it will go off the page\n",
    "require(ggplot2)\n",
    "library(ggplot2)\n",
    "\n",
    "p <- ggplot(data=df, aes(x=full_genome, stat=\"bin\", binwidth=1, fill=host)) + \n",
    "    geom_histogram(position=\"dodge\", binwidth=1)+\n",
    "    geom_vline(xintercept=3, color=duck_color, linetype=2, size=0.7)+\n",
    "    geom_vline(xintercept=9, color=human_color, linetype=2, size=0.7)+\n",
    "    scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12), limits=c(-0.5,12))+\n",
    "    #scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20), limits=c(-0.25,20))+\n",
    "    scale_y_continuous(limits=c(0,100000))+\n",
    "    labs(x=\"\\nnumber of shared sites\",y=\"number of simulations\")+\n",
    "    #ggtitle(\"shared sites in human random simulations (70% of genome tolerates mutation)\") + \n",
    "    scale_fill_manual(values=c(duck_color,human_color))+\n",
    "    theme(plot.title = element_text(size=20, hjust=0.5))+\n",
    "    theme(panel.grid.major.y=element_line(colour=NA))+\n",
    "    theme(panel.grid.minor=element_line(colour=NA,size=NA))+    \n",
    "    theme(strip.background = element_rect(colour=NA, fill=NA))+\n",
    "    theme(axis.line.x=element_line(colour=\"black\"))+\n",
    "    theme(axis.line.y=element_line(colour=\"black\"))+\n",
    "    theme(axis.title.y=element_text(size=16, vjust=8))+\n",
    "    theme(axis.title.x=element_text(size=16, vjust=-8))+\n",
    "    theme(axis.text=element_text(size=16, colour=\"black\"))+\n",
    "    theme(axis.text.x=element_text(size=16))+\n",
    "    theme(legend.text=element_text(size=16))+theme(legend.title=element_text(size=16, face=\"plain\"))+\n",
    "    theme(panel.margin=unit(1, \"lines\"))+theme(plot.margin=unit(c(1,1,1,1),\"cm\"))+\n",
    "    theme(legend.key.size=unit(0.7, \"cm\"))+\n",
    "    theme(panel.background=element_rect(fill=NA))+\n",
    "    theme(legend.key=element_rect(fill=NA))\n",
    "\n",
    "ggsave(\"Fig-3b-shared_sites_perm_test-2019-06-04.pdf\", p, width = 8, height = 5, path=\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/paper-and-figure-drafts/figures-2019-06-04/individual-PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      99991\n",
       "index           99991\n",
       "PB2                 0\n",
       "PB1                 0\n",
       "PA                  0\n",
       "HA                  0\n",
       "NP                  0\n",
       "NA                  0\n",
       "M1                  0\n",
       "M2                  0\n",
       "NS1                 0\n",
       "NEP                 0\n",
       "full_genome      4588\n",
       "host           100000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ducks share 3 sites, humans share 9 sites\n",
    "df_human = df[df['host'] == 'human']\n",
    "df_human[df_human >= 9.0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      99997\n",
       "index           99997\n",
       "PB2                 0\n",
       "PB1                 0\n",
       "PA                  0\n",
       "HA                  0\n",
       "NP                  0\n",
       "NA                  0\n",
       "M1                  0\n",
       "M2                  0\n",
       "NS1                 0\n",
       "NEP                 0\n",
       "full_genome         6\n",
       "host           100000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ducks share 3 sites, humans share 11 sites\n",
    "df_duck = df[df['host'] == 'duck']\n",
    "df_duck[df_duck >= 3.0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "\n",
    "Basically, this tells us that out of 100,000 simulations of random mutations, the vast majority of the time, there will be between 2 and 8 sites that are shared by chance alone in humans, and 0 to 1 sites shared in birds. Some simulations (about 4588) results in at least 9 shared sites in humans, and 6 simulations resulted in >= 3 shared sites in ducks.\n",
    "\n",
    "human p-value: 0.04588\n",
    "duck p-value:  0.00006\n",
    "\n",
    "Both humans and ducks share more variation than expected by chance alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Different percentages of genome mutatable\n",
    "\n",
    "Although this first pass seems like a reasonable way to assess how many shared sites we would expect to see by chance alone, I think it would also be useful to rerun the simulation with a smaller fraction of sites available to mutate. The idea I have here is that the vast majority of codon changes will be so deleterious that you would never expect to observe them in nature. What our results could be showing us is not necessarily that the shared sites we are seeing are mostly driven by adaptation, but rather they reflect random mutations in the small subset of mutations that are actually tolerated for these genes to still produce a functional protein, regardless of host species. So I would like to try out a few different values of limiting the number of possible amino acid site substitutions in line with estimates from the literature. \n",
    "\n",
    "This paper estimates a lethal fraction of about 30%: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5003363/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AJ4MBL718F515_A_Cambodia_X0219301_2013': {'PB2': 370, 'PB1': 369, 'PA': 354, 'HA': 48, 'NP': 241, 'NA': 217, 'M1': 118, 'M2': 43, 'NS1': 100, 'NEP': 51}, 'AJ4MBL720F516_A_Cambodia_X1030304_2013': {'PB2': 350, 'PB1': 236, 'PA': 345, 'HA': 256, 'NP': 238, 'NA': 216, 'M1': 120, 'M2': 44, 'NS1': 106, 'NEP': 53}, 'AJ4MBL718F513_A_CAMBODIA_V0417301_2011': {'PB2': 369, 'PB1': 373, 'PA': 354, 'HA': 238, 'NP': 242, 'NA': 215, 'M1': 118, 'M2': 43, 'NS1': 103, 'NEP': 51}, 'AJ4MBL720F513_A_Cambodia_W0112303_2012': {'PB2': 366, 'PB1': 372, 'PA': 356, 'HA': 242, 'NP': 241, 'NA': 214, 'M1': 119, 'M2': 43, 'NS1': 103, 'NEP': 51}, 'AJ4MBL720F514_A_Cambodia_X0125302_2013': {'PB2': 366, 'PB1': 370, 'PA': 355, 'HA': 111, 'NP': 241, 'NA': 217, 'M1': 119, 'M2': 44, 'NS1': 107, 'NEP': 53}, 'AJ4MBL723F514_A_Cambodia_X0207301_2013': {'PB2': 368, 'PB1': 369, 'PA': 355, 'HA': 244, 'NP': 243, 'NA': 215, 'M1': 119, 'M2': 43, 'NS1': 101, 'NEP': 49}, 'AA4KNL706F512_A_Cambodia_X0128304_2013': {'PB2': 370, 'PB1': 0, 'PA': 345, 'HA': 276, 'NP': 239, 'NA': 216, 'M1': 120, 'M2': 44, 'NS1': 108, 'NEP': 56}, 'AJ4MBL723F512_A_CAMBODIA_V0401301_2011': {'PB2': 370, 'PB1': 367, 'PA': 353, 'HA': 160, 'NP': 235, 'NA': 215, 'M1': 119, 'M2': 43, 'NS1': 106, 'NEP': 51}}\n"
     ]
    }
   ],
   "source": [
    "# Assume that only some fraction of sites could actually have a mutation that you could observe \n",
    "\n",
    "fraction_of_gene_mutation_tolerated = 0.5\n",
    "\n",
    "aa_coverages_human = {}\n",
    "aa_coverages_duck = {}\n",
    "\n",
    "for sample in coverage[\"human\"]: \n",
    "    aa_coverages_human[sample] = {}\n",
    "    for gene in coverage[\"human\"][sample]: \n",
    "        \n",
    "        nuc_sites = coverage[\"human\"][sample][gene]\n",
    "        aa_value = int(nuc_sites/(3 * (1/fraction_of_gene_mutation_tolerated)))\n",
    "        aa_coverages_human[sample][gene] = aa_value\n",
    "\n",
    "for sample in coverage[\"duck\"]: \n",
    "    aa_coverages_duck[sample] = {}\n",
    "    for gene in coverage[\"duck\"][sample]: \n",
    "        \n",
    "        nuc_sites = coverage[\"duck\"][sample][gene]\n",
    "        aa_value = int(nuc_sites/(3 * (1/fraction_of_gene_mutation_tolerated)))\n",
    "        aa_coverages_duck[sample][gene] = aa_value\n",
    "\n",
    "print(aa_coverages_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 100000\n",
    "\n",
    "data_human2 = simulate_shared_sites(SNPs_human2, aa_coverages_human, num_sims)\n",
    "data_duck2 = simulate_shared_sites(SNPs_duck2, aa_coverages_duck, num_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PB2</th>\n",
       "      <th>PB1</th>\n",
       "      <th>PA</th>\n",
       "      <th>HA</th>\n",
       "      <th>NP</th>\n",
       "      <th>NA</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>NS1</th>\n",
       "      <th>NEP</th>\n",
       "      <th>full_genome</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PB2  PB1  PA  HA  NP  NA  M1  M2  NS1  NEP  full_genome   host\n",
       "0      0    2    2   2   5   2   1   0   1    0    0           15  human\n",
       "1      1    2    0   0   1   1   1   1   1    0    0            7  human\n",
       "2      2    1    1   2   6   3   1   0   0    0    0           14  human\n",
       "3      3    1    2   1   5   0   2   1   0    0    0           12  human\n",
       "4      4    1    1   0   3   0   2   1   0    0    0            8  human"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "df_human2 = pd.DataFrame(data_human2, columns=data_human2.keys())\n",
    "df_human2 = df_human2.reset_index()\n",
    "df_human2[\"full_genome\"] = df_human2['PB2'] + df_human2['PB1'] + df_human2['PA'] + df_human2['HA'] + df_human2['NP'] + df_human2['NA'] + df_human2['M1'] + df_human2['M2'] + df_human2['NS1'] + df_human2['NEP']\n",
    "df_human2[\"host\"] = \"human\"\n",
    "\n",
    "df_duck2 = pd.DataFrame(data_duck2, columns=data_duck2.keys())\n",
    "df_duck2 = df_duck2.reset_index()\n",
    "df_duck2[\"full_genome\"] = df_duck2['PB2'] + df_duck2['PB1'] + df_duck2['PA'] + df_duck2['HA'] + df_duck2['NP'] + df_duck2['NA'] + df_duck2['M1'] + df_duck2['M2'] + df_duck2['NS1'] + df_duck2['NEP']\n",
    "df_duck2[\"host\"] = \"duck\"\n",
    "\n",
    "df2 = pd.concat([df_human2, df_duck2])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-70-percent-2019-06-04.txt\", sep='\\t')\n",
    "df2.to_csv(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-50-percent-2019-06-04.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>PB2</th>\n",
       "      <th>PB1</th>\n",
       "      <th>PA</th>\n",
       "      <th>HA</th>\n",
       "      <th>NP</th>\n",
       "      <th>NA</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>NS1</th>\n",
       "      <th>NEP</th>\n",
       "      <th>full_genome</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  PB2  PB1  PA  HA  NP  NA  M1  M2  NS1  NEP  full_genome  \\\n",
       "0           0      0    1    3   1   3   1   0   0   0    0    0            9   \n",
       "1           1      1    1    2   0   0   1   1   0   0    0    0            5   \n",
       "2           2      2    1    1   3   3   3   3   1   0    0    0           15   \n",
       "3           3      3    2    1   1   1   0   1   0   0    0    0            6   \n",
       "4           4      4    0    0   1   2   1   1   0   0    0    0            5   \n",
       "\n",
       "    host  \n",
       "0  human  \n",
       "1  human  \n",
       "2  human  \n",
       "3  human  \n",
       "4  human  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataframe back in \n",
    "df2 = pd.read_table(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-70-percent-2019-06-04.txt\", sep=\"\\t\")\n",
    "#df2 = pd.read_table(\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/shared_variant_analyses/simulations-50-percent-2019-06-04.txt\", sep=\"\\t\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "%%R -w 800 -h 500 -u px -i df2,human_color,duck_color  # this sets the size of the plot...otherwise, it will go off the page\n",
    "require(ggplot2)\n",
    "library(ggplot2)\n",
    "\n",
    "p2 <- ggplot(data=df2, aes(x=full_genome, stat=\"bin\", fill=host)) + \n",
    "    geom_histogram(position=\"dodge\", binwidth=1)+\n",
    "    geom_vline(xintercept=3, color=duck_color, linetype=2, size=0.7)+\n",
    "    geom_vline(xintercept=9, color=human_color, linetype=2, size=0.7)+\n",
    "    scale_x_continuous(limits=c(-0.5,20), breaks=c(0,2,4,6,8,10,12,14,16,18,20))+  \n",
    "    scale_y_continuous(limits=c(0,100000))+\n",
    "    labs(x=\"\\nnumber of shared sites\",y=\"number of simulations\")+\n",
    "    scale_fill_manual(values=c(duck_color,human_color))+\n",
    "    theme(plot.title = element_text(size=20, hjust=0.5))+\n",
    "    theme(panel.grid.major.y=element_line(colour=NA))+\n",
    "    theme(panel.grid.minor=element_line(colour=NA,size=NA))+    \n",
    "    theme(strip.background = element_rect(colour=NA, fill=NA))+\n",
    "    theme(axis.line.x=element_line(colour=\"black\"))+\n",
    "    theme(axis.line.y=element_line(colour=\"black\"))+theme(strip.text.x=element_text(size=11))+\n",
    "    theme(axis.title.y=element_text(size=16, vjust=8))+\n",
    "    theme(axis.title.x=element_text(size=16, vjust=-8))+\n",
    "    theme(axis.text=element_text(size=16, colour=\"black\"))+\n",
    "    theme(axis.text.x=element_text(size=16))+\n",
    "    theme(legend.text=element_text(size=16))+theme(legend.title=element_text(size=16, face=\"plain\"))+\n",
    "    theme(panel.margin=unit(1, \"lines\"))+theme(plot.margin=unit(c(1,1,1,1),\"cm\"))+\n",
    "    theme(legend.key.size=unit(0.7, \"cm\"))+\n",
    "    theme(panel.background=element_rect(fill=NA))+\n",
    "    theme(legend.key=element_rect(fill=NA))\n",
    "\n",
    "ggsave(\"Fig-3c-shared_sites_perm_test_70_percent-2019-06-04.pdf\", p2, width = 8, height = 5, path=\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/paper-and-figure-drafts/figures-2019-06-04/individual-PDFs\")\n",
    "#ggsave(\"Fig-3d-shared_sites_perm_test_50_percent-2019-06-04.pdf\", p2, width = 8, height = 5, path=\"/Users/lmoncla/Documents/H5N1_Cambodian_outbreak_study/paper-and-figure-drafts/figures-2019-06-04/individual-PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      99991\n",
       "index           99991\n",
       "PB2                 0\n",
       "PB1                 0\n",
       "PA                  0\n",
       "HA                 15\n",
       "NP                  0\n",
       "NA                  0\n",
       "M1                  0\n",
       "M2                  0\n",
       "NS1                 0\n",
       "NEP                 0\n",
       "full_genome     60771\n",
       "host           100000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human2 = df2[df2['host'] == 'human']\n",
    "df_human2[df_human2 >= 9.0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      99997\n",
       "index           99997\n",
       "PB2                 0\n",
       "PB1                 0\n",
       "PA                  0\n",
       "HA                  0\n",
       "NP                  0\n",
       "NA                  0\n",
       "M1                  0\n",
       "M2                  0\n",
       "NS1                 0\n",
       "NEP                 0\n",
       "full_genome        51\n",
       "host           100000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duck2 = df2[df2['host'] == 'duck']\n",
    "df_duck2[df_duck2 >= 3.0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "**70% of the genome can have a mutation:**\n",
    "\n",
    "23,234 out of 100,000 simulations had at least 9 sites shared in humans: p = 0.23234\n",
    "\n",
    "14 simulations had at least 3 sites shared in ducks: p = 0.00014\n",
    "\n",
    "**50% of the genome can have a mutation:**\n",
    "\n",
    "60,771 out of 100,000 simulations had at least 9 sites shared in humans: p = 0.608\n",
    "\n",
    "51 simulations had at least 3 shared sites in ducks: p = 0.00051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "H5N1_v2",
   "language": "python",
   "name": "h5n1_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
